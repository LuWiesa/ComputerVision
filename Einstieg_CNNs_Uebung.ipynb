{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Einstieg in CNNs\n",
    "\n",
    "Im ersten Teil (1. Einstieg in Neuronale Netzwerke) wurden bereits Neuronale Netze mit der Keras-Schnittstelle angelegt. In diesem Teil werden die Vorteile und Besonderheiten von Convolutional-Neuronal-Networks (CNN) behandelt.\n",
    "\n",
    "In diesem Notbeook werden folgende Themen behandelt\n",
    "- Einführung CNNs\n",
    "- Data Augmentation\n",
    "- Besonderheiten farbige Bilder\n",
    "- Visualisierung der Zwischenergebnisse\n",
    "\n",
    "Als Beispieldatensatz wird auch hier der MNIST-Datensatz verwendet.\n",
    "\n",
    "*Überprüfen Sie zunächst, ob Sie eine Tensorflow-Version > 2.0 verwenden*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfen der Installation\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ausgeben der Version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a-1) Erstellen eines CNNs\n",
    "\n",
    "Auch Convolutional Layer lassen sich sehr leicht mit der Keras-API hinzufügen.  \n",
    "\n",
    "Hierfür muss das Datenformat leicht angepasst werden: Da die **Convolutional-Layer** mit farbigen Bildern (3 Farbkanäle) und mit Grauwertbildern (1 Farbkanal) arbeiten, müssen die Farbkanäle als eigene Dimension eingefügt werden.\n",
    "Statt der Dimension der ursprünglichen Bilddaten (28,28) wird die Dimension (28,28,1) verwendet.\n",
    "\n",
    "Bsp: Dimensionumwandlung Graustufen (2,2) zu (2,2,1)\n",
    "$$ \\left[ \\begin{matrix} 0.2 & 0 \\\\ 0.5 & 0.7 \\end{matrix} \\right]  \\rightarrow \\left[ \\begin{matrix} [0.2] & [0] \\\\ [0.5] & [0.7] \\end{matrix} \\right] $$ \n",
    "Bsp. (2,2,3) Farbstufenmatrix $$ \\left[ \\begin{matrix} [0.2, 0.1,0.5] & [0.4,0.8,0.1] \\\\ [0.2, 0.1,0.7] &  [0.2, 0.1,0.7] \\end{matrix} \\right] $$\n",
    "\n",
    "Führen Sie den folgenden Programmcode aus und beantworten Sie dabei folgende Fragen:\n",
    "* Der Aufruf padding=’same‘ bewirkt, dass die Randpixel der Bilder kopiert werden, die Bilder also zwei Zeilen und zwei Spalten vergrößert werden. Warum ist das notwendig?\n",
    "* Wie viele Faltungsmatrizen werden in der ersten Convolutional Layer verwendet?\n",
    "\n",
    "**Hinweis: Das Ausführen des Programms kann mehrere Minuten dauern - Zeit für einen Kaffee oder zum Nachdenken über die Reflexionsfragen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# Setzen des Seeds - Zur Reproduktion, da die initalen Gewichte zufällig gesetzt werden\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "# Laden des Datensatzes\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normieren des Datensatzes (Werte zwischen 0-1)\n",
    "x_train =  x_train / 255.0\n",
    "x_test  =  x_test / 255.0\n",
    "print(\"Dimension x_train:\",x_train.shape)\n",
    "\n",
    "# Umformen der Daten (Menge, Zeilen, Spalten, Channels (1 = Grauwert))\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28 , 1)\n",
    "x_test =x_test.reshape(x_test.shape[0], 28, 28 , 1)\n",
    "    \n",
    "# Hinzufügen der Schichten in Keras\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Convolutional Layer + MaxPooling\n",
    "    tf.keras.layers.Conv2D(32,(5,5), activation='relu', padding=\"same\", input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(6,6),padding=\"same\", strides=(2,2)),\n",
    "    # Convolutional Layer + MaxPooling\n",
    "    tf.keras.layers.Conv2D(64,(5,5), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(4,4),padding=\"same\", strides=(2,2)),\n",
    "    # Übergang Klassifikator\n",
    "    tf.keras.layers.Flatten(),                        \n",
    "    tf.keras.layers.Dense(720, use_bias=True,activation='relu'),   \n",
    "    tf.keras.layers.Dense(10)                         \n",
    "])\n",
    "\n",
    "# Anlegen einer Verlustfunktion: Kreuzentropie wegen Kategorien\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Anlegen eines Optimiziers\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Kompilieren des Modells und Auswahl des Optimizers\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trainieren des Modells\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=150, validation_data=(x_test,y_test),validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zusatzaufgabe** Finden Sie heraus, wie viele trainierbare Parameter das Modell besitzt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Das benutzte model()-Objekt stammt aus dem Abschnitt a-1. Bitte führe den Abschnitt vor diesem Teil aus.*\n",
    "\n",
    "### a-2) Vorhersage von augmentierten Daten\n",
    "\n",
    "Im vorherigen Aufgabenteil konnte ein FCNN alleine nicht gegen leicht abgeänderte Daten bestehen.\n",
    "Durch ihren Aufbau sind CNNs gegen bestimmte Veränderungen robuster. Probieren Sie es aus!\n",
    "\n",
    "*Zur Erinnerung:* In diesem Teil wird das Bildzentrum in die x- und y-Richtung um eine zufällige Zahl im Intervall $[-8, +8]$ verschoben. In der x-Richtung wäre -8 eine maximale Verschiebung um 8 Pixel nach links. Beispielsweise kann die Verschiebung wie folgt aussehen:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Machen Sie sich zu folgenden Themen Gedanken:\n",
    "* Was bewirkt das Pooling? Was bedeuten die Optionen in für die angelegte Pooling-Schicht (`max_pooling2d`)?\n",
    "* Welche Grundidee wurde aus der analytischen Computer Vision durch das Pooling realisiert? Erklären Sie den Effekt bezüglich Skalierung und Translation, den man durch das Pooling erzielt im Hinblick auf die Objekterkennung in den Bildern. \n",
    "\n",
    "**Zusatz:** Experimentieren Sie mit den Pooling Kernel. Kann das Erkennen von verschobenen Ziffern noch verbessert werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Funktion zum Agumentieren\n",
    "def augment(image):\n",
    "    image = np.array(image).reshape((28, 28, 1))\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 36, 36) # Hinzufügen von 8 Pixeln Rahmen\n",
    "    image = tf.image.random_crop(image, size=[28, 28, 1])  # Zufälliges Zurückschneiden auf 28 x 28\n",
    "    return image\n",
    "\n",
    "for i in range(10):\n",
    "    # Visualisierung unverändertes Bild\n",
    "    image = x_test[i]\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.title(\"Unverändertes Bild (Label {})\".format(y_test[i]))\n",
    "    plt.show()\n",
    "    \n",
    "    # Prognose unverändertes Bild\n",
    "    predictions = model(np.array(x_test[i]).reshape(1,28,28,1)).numpy()\n",
    "    probs = tf.nn.softmax(predictions).numpy()\n",
    "    print(\"Prognose: \\t\", np.argmax(probs[0]))\n",
    "    \n",
    "    # Visualisierung verändertes Bild\n",
    "    aug_image = augment([x_test[i]])\n",
    "    pixels = np.array(aug_image).reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.title(\"Augmentierte Bild\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Prognose verändertes Bild\n",
    "    predictions = model(np.array(pixels).reshape(1,28,28,1)).numpy()\n",
    "    probs = tf.nn.softmax(predictions).numpy()\n",
    "    print(\"Prognose: \\t\", np.argmax(probs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Data Augmentation\n",
    "\n",
    "In diesem Abschnitt lernen Sie weitere Möglichkeiten kennen, die Datenmenge für ihr Netz durch Augmentieren zu Vergößern.\n",
    "Die aufgeführten Operationen sind für Grauwertbilder geeignet und stellen nur eine Auswahl der Möglichkeiten dar.\n",
    "\n",
    "Fragen zum Nachdenken\n",
    "* Welche weiteren Operationen sind bei Grauwert-Bildern möglich?\n",
    "* Welche weiteren Operationen sind bei Farbbildern möglich?\n",
    "* Welche Grenzen hat Data Augmentation? Finde ein Beispiel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl eines Bilder\n",
    "image = x_test[1]\n",
    "\n",
    "# Anzeigen des Original Bildes\n",
    "plt.imshow(np.array(image).reshape((28, 28)), cmap='gray')\n",
    "plt.title(\"Original\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Spiegelungen (falls anwendbar)\n",
    "flipped = tf.image.flip_left_right(image)\n",
    "           \n",
    "# Rotation\n",
    "rotated = tf.image.rot90(image)\n",
    "\n",
    "# Translation \n",
    "def shift6px(image):\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 34, 34)  # 6 Pixel Rahmen \n",
    "    image = tf.image.random_crop(image, size=[28, 28, 1])    # Zurückschneiden auf 28x28\n",
    "    return image\n",
    "\n",
    "# Skalierung\n",
    "cropped = tf.image.central_crop(image, central_fraction=0.7)\n",
    "\n",
    "# Verschieben der Bildmitte\n",
    "shifted = shift6px(image)\n",
    "\n",
    "# Helligkeit\n",
    "bright = tf.image.adjust_brightness(image,0.1)\n",
    "\n",
    "# Gaußsches Rauschen\n",
    "def gaussian_noise_layer(image):\n",
    "    noise = tf.keras.backend.random_normal(shape=tf.shape(image), mean=0.0, stddev=0.1) \n",
    "    return image + noise\n",
    "noise = gaussian_noise_layer(image)\n",
    "\n",
    "\n",
    "# Visualisieren der abgeänderten Bilder\n",
    "fig, axs = plt.subplots(2, 3,figsize=(10,7))\n",
    "\n",
    "# Augmentierte Bilder\n",
    "axs[1,0].imshow(np.array(shifted).reshape((28, 28)), cmap='gray')\n",
    "axs[1,0].set_title(\"Verschoben\")\n",
    "axs[1,1].imshow(np.array(bright).reshape((28, 28)), cmap='gray',vmin=0, vmax=1)\n",
    "axs[1,1].set_title(\"Heller\")\n",
    "axs[1,2].imshow(np.array(cropped).reshape((20,20)), cmap='gray',vmin=0, vmax=1)\n",
    "axs[1,2].set_title(\"Zoom\")\n",
    "axs[0,0].imshow(np.array(noise).reshape((28, 28)), cmap='gray')\n",
    "axs[0,0].set_title(\"Rauschen\")\n",
    "axs[0,1].imshow(np.array(rotated).reshape((28, 28)), cmap='gray')\n",
    "axs[0,1].set_title(\"90 Grad gedreht\")\n",
    "axs[0,2].imshow(np.array(flipped).reshape((28, 28)), cmap='gray')\n",
    "axs[0,2].set_title(\"Vertikal gespiegelt\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis: Das Ausführen des Programms kann eine ganze Weile dauern - Zeit für einen Kaffee oder zum Nachdenken über die Reflexionsfragen**\n",
    "\n",
    "### Zusatz) Mehrfarbiges Bild\n",
    "\n",
    "Im folgenden wird der [CIFAR-Datensatz](https://www.cs.toronto.edu/~kriz/cifar.html) analysiert. Dieser Datensatz besteht aus farbigen 32x32 Pixel Bildern mit 10 verschiedenen Motiven wie Flugzeugen, Fröschen und Autos. Auch diese Daten können einfach über Tensorflow in das Notebook geladen werden. Als Alternative können die Daten auch von der Website geladen werden und über den Dateipfad in das Notebook integriert werden.\n",
    "\n",
    "Folgende Fragen helfen Ihnen beim Verständis:\n",
    "* Was ist anders im Gegensatz zu dem MNIST-Datensatz?\n",
    "* Informiere dich, wie die Faltung in den Convolutional Layern bei farbigen Bildern abläuft.\n",
    "* Welche Dimensionen haben die Schichten? Wie viele Parameter werden hier trainiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# Laden der Bilddateb\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalisieren der Bildaten\n",
    "train_images = train_images / 255.0\n",
    "test_images =  test_images / 255.0\n",
    "\n",
    "labels = ['Flugzeug','Auto','Vogel','Katze','Reh','Hund','Forsch','Pferd','Schiff','Truck']\n",
    "\n",
    "# Visualisieren der ersten 25 Bilder\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(labels[train_labels[i][0]]) # Labels sind eine verschachtelte Array [[1]]\n",
    "plt.show()\n",
    "\n",
    "# Alternatives Anlegen eines Modells mit model.add(LAYER)\n",
    "model_cifar = models.Sequential()\n",
    "# Convolutional Layers\n",
    "model_cifar.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model_cifar.add(layers.MaxPooling2D((2, 2)))\n",
    "model_cifar.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_cifar.add(layers.MaxPooling2D((2, 2)))\n",
    "model_cifar.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# Klassifikator\n",
    "model_cifar.add(layers.Flatten())\n",
    "model_cifar.add(layers.Dense(64, activation='relu'))\n",
    "model_cifar.add(layers.Dense(10))\n",
    "\n",
    "model_cifar.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_cifar.fit(train_images, train_labels, epochs=8, \n",
    "                    validation_data=(test_images, test_labels),batch_size=150,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung von Filtern der Neuronalen Netzwerke\n",
    " \n",
    "Folgender Code extrahiert die Filter-Gewichte aus der ersten Convolutional-Layer des trainierten CNNs. Diese werden anschließend visualisiert. Schauen Sie sich die Filter genauer an, erkennen Sie gängige Faltungskerne?\n",
    "\n",
    "[Hier](https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/) gibt es mehr zum Thema Filter-Visualisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_cifar.layers:\n",
    "    # Ausführung nur für Convolutional Layer\n",
    "    if 'conv' in layer.name:\n",
    "        # Speichern der Gewichte \n",
    "        filters, biases = layer.get_weights()\n",
    "        \n",
    "        # Ausgabe der Dimensionen: 32 Filterkerne\n",
    "        print(\"Dimensionen Gewichte 1. Conv-Layer\", filters.shape)\n",
    "        \n",
    "        # Anlegen eines Subplots\n",
    "        fig, axs = plt.subplots(8, 4,figsize=(8,10))\n",
    "        ix = 0\n",
    "        \n",
    "        print(\"Visualisierung der 32 Filter der ersten Schicht:\")\n",
    "        for zeile in range(8):\n",
    "            for spalte in range(4):\n",
    "                # Visualisieren eines Filters\n",
    "                f = filters[:, :, 0, ix].reshape(3,3) # !Auswahl nur einer Farbe \n",
    "                axs[zeile, spalte].imshow(f,cmap='Reds')\n",
    "                axs[zeile, spalte].set_xticks([])\n",
    "                axs[zeile, spalte].set_yticks([])\n",
    "                ix = ix + 1\n",
    "                \n",
    "        # Ausstieg, da nur eine Schicht visualisiert wird\n",
    "        break\n",
    "                \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung von Feature-Maps der Neuronalen Netzwerke\n",
    "\n",
    "Die Zwischenschritte in CNNs werden auch Feature-Maps genannt und lassen sich ebenfalls visualisieren.\n",
    "Im folgenden Code wird die Featuremap nach der ersten Schicht (Convolutional Layer und Max-Pooling-Layer) ausgegeben.\n",
    "\n",
    "In dem Codeteil `outputs=model_fm.layers[1].output`wird festgelegt, nach welcher Schicht die Ausgabe erfolgen soll.\n",
    "Folglich können Sie auch die Ausgabe nach der 2. oder 3. Convolutional Layer betrachten, in dem Sie die Output-Schicht entsprechend definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Modells\n",
    "model_fm = model_cifar\n",
    "\n",
    "# Anpassen des Modells (Output nach erster 2. Schicht (Max-Pooling)\n",
    "model_fm = tf.keras.models.Model(inputs=model_fm.inputs, outputs=model_fm.layers[1].output)\n",
    "print(\"Struktur des angelegten Modells\")\n",
    "model_fm.summary()\n",
    "\n",
    "# Auswahl eines Bilders\n",
    "img = train_images[0]\n",
    "\n",
    "# Anzeigen des Bildes\n",
    "plt.imshow(img.reshape(32,32,3))\n",
    "plt.title(\"Ausgewähltes Bild\")\n",
    "plt.show()\n",
    "\n",
    "feature_maps = model_fm.predict(img.reshape(1,32,32,3))\n",
    "feature_maps.shape\n",
    "\n",
    "# Anlegen eines Subplots\n",
    "fig, axs = plt.subplots(8, 4,figsize=(8,10))\n",
    "ix = 0\n",
    "\n",
    "print(\"Visualisierung der Feature-Maps der ersten Schicht:\")\n",
    "for zeile in range(8):\n",
    "    for spalte in range(4):\n",
    "        # Visualisieren einer Feature-Map\n",
    "        f = feature_maps[0,:,:, ix].reshape(15,15)\n",
    "        axs[zeile, spalte].imshow(f,cmap='gray')\n",
    "        axs[zeile, spalte].set_xticks([])\n",
    "        axs[zeile, spalte].set_yticks([])\n",
    "        ix = ix + 1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusatzaufgabe) Erstellen eines eignen CNNs\n",
    "\n",
    "Jetzt sind Sie an der Reihe! Erstellen Sie ihr eignes Netz mit Faltungsschichten. Verwende dafür den MNIST-Fashion-Datensatz.\n",
    "\n",
    "**Aufgaben**\n",
    "* Normieren Sie die Pixelwert auf den Bereich (0-255)\n",
    "* Wandelen Sie die Dimension der Daten um (28,28,1)\n",
    "* Entwerfen Sie ein 5-Schichten-Modell: \n",
    "  - Die *Input-Layer* muss das 2D-Bild in einen 1D-Vektor überführen. \n",
    "  - Eine *Convolutional-Layer* mit MaxPooling\n",
    "  - Der *Flatten-Layer* bildet den Übergang zum Klassifikator\n",
    "  - Die *Hidden-Layer* kann beliebig (aber sinnvoll!) gewählt werden.\n",
    "  - Die *Output-Layer* muss in den Dimensionen mit der Zielvariable y übereinstimmen.\n",
    "* Kompilieren Sie das Modell mit einem Optimizier, einer Verlustfunktion (passend zu den One-Hot-Encoding der y-Werte!) und der Metrik 'accuracy'\n",
    "* Trainieren Sie das Modell\n",
    "\n",
    "**Tipp** Da das Modell in einigen Fällen nicht konvergiert, können Sie folgende Hilfestellungen veruschen\n",
    "- Optimizier `tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)`\n",
    "- Kernel-Inializier `kernel_initializer='he_uniform'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "# Setzen des Seeds (zufällige Initalisierung der Gewichte)\n",
    "seed(56)\n",
    "tf.random.set_seed(56)\n",
    "\n",
    "# Laden der Daten\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# OneHot-Encoding für die Zielvariablen\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Anlegen der Labels\n",
    "labels = [\"T-Shirt/Top\",\"Hose\",\"Pullover\",\"Kleid\",\"Jacke\",\"Sandalen\", \"Shirt\",\"Sneaker\",\"Handtasche\",\"Stiefel\"]\n",
    "\n",
    "# Visualisieren des ersten Bildes\n",
    "image = 13  # Ändern zum Anzeigen eines beliebigen Bildes\n",
    "pixels = x_test[image].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.title(\"Beispielhaftes Bild\")\n",
    "plt.show()\n",
    "\n",
    "##### Ergänze den Code unter dieser Zeile ###############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "computervision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
